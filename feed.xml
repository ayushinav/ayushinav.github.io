<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ayushinav.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ayushinav.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-09T22:51:03+00:00</updated><id>https://ayushinav.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">GSoC’24</title><link href="https://ayushinav.github.io/blog/2024/gsoc24/" rel="alternate" type="text/html" title="GSoC’24"/><published>2024-08-25T16:40:16+00:00</published><updated>2024-08-25T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2024/gsoc24</id><content type="html" xml:base="https://ayushinav.github.io/blog/2024/gsoc24/"><![CDATA[<h2 id="summary">Summary</h2> <p>During the 2024 iteration of Google Summer of Codes, I worked towards building the package <code class="language-plaintext highlighter-rouge">NeuralOperators.jl</code>. The package now export architectures of DeepONets, Fourier Neural Operators (FNOs), and Nonlinear Manifold Decoders (NoMADs). I began my work by implementing the vanilla <code class="language-plaintext highlighter-rouge">DeepONet</code> architecture, similar to the one provided by <a href="https://github.com/lululxvi/deepxde">deepxde</a>, except that we allow for batching that does not emply different routines for aligned and non-aligned datasets.</p> <ul> <li>PR merged : <a href="https://github.com/LuxDL/NeuralOperators.jl/pull/5">#5</a></li> </ul> <p>The next step began with the opening of the issue <a href="https://github.com/LuxDL/NeuralOperators.jl/issues/9">#9</a>, that requires an <code class="language-plaintext highlighter-rouge">additional</code> layer added to the DeepONet architecture, before we project the learnt basis onto the output space. This extends the utility of the architecture by adding the capability to learn operators that output in higher dimensions, without collapsing information.</p> <ul> <li>PR merged : <a href="https://github.com/LuxDL/NeuralOperators.jl/pull/15">#15</a></li> </ul> <p>Another major task that I accomplished was adding NOMADs, that took the package one step closer to achieving the feature parity with respect to the would-be deprecated last release of <code class="language-plaintext highlighter-rouge">SciML/NeuralOperators.jl</code> . This was relatively simpler considering I had a decent experience already implementing architectures in the package.</p> <ul> <li>PR merged : <a href="https://github.com/LuxDL/NeuralOperators.jl/pull/27">#27</a></li> </ul> <p>Another PRs that added more organization to the package and bringing coherency were:</p> <ul> <li>PR merged : <a href="https://github.com/LuxDL/NeuralOperators.jl/pull/4">#4</a></li> <li>PR merged : <a href="https://github.com/LuxDL/NeuralOperators.jl/pull/23">#23</a></li> </ul> <p>One task that took me a lot of time and I’m still yet to figure out completely is the addition of the continuous variant of the neural operator. Propagating the Borel measures of the functions held me for a bit before I realized it would be more worthwhile to invest time in adding more features to the package that would be used more frequently. The PR on the same is still a work in progress and I intend to add it after we have added a few other operators, which would be relatively easier for me considering the experience I have built during the period.</p> <ul> <li><a href="https://github.com/LuxDL/NeuralOperators.jl/pull/10">PR #10</a> : Integral Kernel Operator</li> </ul> <p>We have also compared the performance of the package with the already developed versions in python. While the FNO requires some optimizations, DeepONet is already 10x faster compared to its pytorch counterpart. While it’s a PR in the package, this will be added to <a href="https://docs.sciml.ai/SciMLBenchmarksOutput/stable/">SciMLBenchmarks.jl</a></p> <ul> <li><a href="https://github.com/LuxDL/NeuralOperators.jl/pull/17">PR #17</a> : Benchmark Tests for FNO and DeepONets</li> </ul> <p>Documentation for the package are also underway and would be built for hosting soon, along with the tutorials to help users integrate it into the works seemlessly.</p> <ul> <li><a href="https://github.com/LuxDL/NeuralOperators.jl/pull/24">PR #24</a> : Documentation</li> </ul> <h2 id="more-todos">More TODOs</h2> <p>There are a plethora of Neural Operators out there that can be added. <a href="https://arxiv.org/abs/2009.12935">DeepM&amp;MNets</a>, <a href="https://arxiv.org/abs/2204.11127">U-shaped NOs</a>, and many more… With <a href="https://github.com/CarloLucibello/GraphNeuralNetworks.jl/issues/372">GraphNeuralNetworks.jl/#32</a> being merged, adding Graph Neural Operators is the next task in the list to achieve feature parity and release the updated version of the package. The continuous variant of the neural operator is something that has challenged me and adding it would be major feat for me.</p>]]></content><author><name></name></author><category term="gsoc"/><category term="code"/><category term="math"/><summary type="html"><![CDATA[Summary of GSoC'24]]></summary></entry><entry><title type="html">Markov Chain Monte Carlo</title><link href="https://ayushinav.github.io/blog/2024/mcmc/" rel="alternate" type="text/html" title="Markov Chain Monte Carlo"/><published>2024-08-19T16:40:16+00:00</published><updated>2024-08-19T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2024/mcmc</id><content type="html" xml:base="https://ayushinav.github.io/blog/2024/mcmc/"><![CDATA[<h1 id="metropolis-acceptance">Metropolis acceptance</h1> <p>Markov Chain Monte Carlo (MCMC) does not need an introduction honestly. It is used to generate samples from a “target” probability distribution \(f(x)\), which is not really easy to sample. MCMC does so by constructing a Markov Chain, that is generating a new sample is only conditioned on the previous sample. More formally, this can be written as</p> \[\mathrm{P}(x^{i+1} | x^i, x^{i-1},..., x^{1}) = \mathrm{P}(x^{i+1} | x^i) = g(x^{i+1} | x^i)\] <p>where \(g( \cdot | x^i)\) is called the “proposal” distribution, and it proposes new samples from the prior distribution. The right choice of the proposal affects the convergence of MCMC. We start with the case when this proposal is symmetric, that is, there is an as chance of moving of \(x^i \rightarrow x^j\) as of \(x^j \rightarrow x^i\), that is,</p> \[g(x^{i+1} | x^i) = g(x^{i} | x^{i+1})\] <p>But for any distributions that follow the symmetry of \(g( \cdot | x^i)\), the MCMC defines a Metropolis ratio, which determines whether a proposed sample will be accepted or not. The candidate proposal \(x^*\) is accepted with the probability</p> \[\alpha(x^i, x^*) = \min \left(1, \frac{f(x^*)}{f(x^i)} \right)\] <p>Intuitively, this means that the candidate is always accepted if it is moving to a higher probability region, and is only sometimes accepted when going to the lower probability areas. The ratio inside \(\min\) is called the Metropolis ratio.</p> <h2 id="detailed-balance-and-stationary-distribution">Detailed balance and stationary distribution</h2> <p>Our objective from MCMC is to sample the posterior distribution, i.e., the samples generated at i-th and (i+1)-th step belong to the same distribution. Such a distribution which after a transition step comes back to itself is called a stationary distribution of that Markov chain. We want this stationary distribution to be the distribution we sample from. Any ergodic Markov chain that has the detailed balance sufficiently has a target stationary distribution. The detailed balance is defined as:</p> <p>\(f(x) T(x,y) = f(y) T(y,x) \implies f(x^i = x) T(x^i = x, x^{i+ 1} = y) = f(x^i = y) T(x^i= y, x^{i+1} = y)\) where \(T(x,y)\) is the transition matrix from state \(x\) to \(y\), which for our case is \(g(y|x)\) . In order to show that such a chain has a stationary distribution, we have</p> \[\begin{aligned} f_{i+1}(y) &amp;= \sum_x f_{i}(x) T(x, y) \quad \text{OR} \sum_x f_{i}(x^i = x) T(x^i = x, x^{i+ 1} = y) \\ &amp; \text{(Expressing as marginal distribution)} \\ &amp;= \sum_x f_{i}(y) T(y, x) \quad \text{OR} \sum_x f_{i}(x^i = y) T(x^i = y, x^{i+ 1} = x) \\ &amp; \text{(By detailed balance)} \\ &amp;= f_{i}(y) \sum_x T(y, x) \quad \text{OR} f_{i}(x^i = y) \sum_x T(x^i = y, x^{i+ 1} = x) \\ &amp;= f_{i}(y) \\ &amp; \text{(The summand is the sum of probabilities from any obtained value in state} x^{i} \text{ to } x^{i+1} = j, \text{which should be 1)} \\ \end{aligned}\] <p>Intuitively, detailed balance states that moving from state \(x\) to state \(y\) is as likely as the other way round, this also implies reversibility. Detailed balance enforces that the under condition of ergodicity, if the chain samples from a distribution at i-th step, it will do so in the next step.</p> <p>Now, in Metropolis algorithm, the transition probability is given by</p> \[\begin{aligned} T(x^i, x^*) &amp;= g(x^* | x^i) \alpha(x^i, x^*) \\ &amp;= g(x^* | x^i) \min \left(1, \frac{f(x^*)}{f(x^i)} \right) \\ \therefore &amp; \text{(From detailed balance)} \\ f(x^i) T(x^i, x^*) &amp;= f(x^i) g(x^* | x^i) \min \left(1, \frac{f(x^*)}{f(x^i)} \right) \\ &amp;= g(x^* | x^i) \min \left(f(x^i), f(x^*) \right) \\ &amp;= g(x^i | x^*) \min \left(f(x^i), f(x^*) \right) \\ &amp; (g(\cdot | \cdot) \text{is symmeteric for Metropolis algorithm})\\ &amp;= f(x^*) g(x^i | x^*) \min \left(1, \frac{f(x^i)}{f(x^*)} \right) \\ &amp;= f(x^*) T(x^*, x^i) \end{aligned}\] <p>Therefore, the Metropolis algorithm always has the stationary distribution defined by the “target” distribution. Though starting from a random prior point, it takes a few iterations to get to the space of exploring the posterior. This period is called burn-in and the samples generated during the time are generally ignored.</p> <p>Before we go further, the following are special cases of Metropolis algorithm.</p> <h2 id="random-walk-metropolis">Random Walk Metropolis</h2> <p>Random Walk Metropolis is a special case of the above when we choose \(g(x^i|x^j) = h(x^i -x^j)\), an example of \(h(\cdot)\) would be the normal distribution, eg.</p> <p>\(g(x^{j} | x^i) = h(x^j- x^i) = \mathrm{N}(x^j- x^i, \sigma^2) \quad \text{or} \quad x^j \sim \mathrm{N}(x^i, \sigma^2)\) We, therefore, propose a new sample that is in the vicinity of the prebious one by taking small steps, defined by \(\sigma\), in random directions. This works for simple problems, but even the step-size needs to be adequate. If it’s too small, we’re not exploring the prior space, if it’s too large, we’re wasting a lot of time on samples that may not be accepted.</p> <h2 id="independent-chain">Independent chain</h2> <p>Independent chain is another sub-class which allows the proposal to be independent of the previous state.</p> \[g(x^{j} | x^i) = h(x^j)\] <p>This might work only for very specific cases.</p> <h1 id="metropolis-hastings">Metropolis-Hastings</h1> <p>While Metropolis requires the proposal distribution \(g(\cdot | \cdot)\) be symmetric, this is not necessarily required for MCMC. In case of assymetric proposal, we modify the acceptance as:</p> \[\alpha(x^i, x^*) = \min \left(1, \frac{f(x^*) g(x^i | x^*)}{f(x^i) g(x^* | x^i)} \right)\] <p>To show that MH also has detailed balance, we have</p> \[\begin{aligned} f(x^i) T(x^i, x^*) &amp;= f(x^i) g(x^* | x^i) \min \left(1, \frac{f(x^*) g(x^i | x^*)}{f(x^i) g(x^* | x^i)} \right) \\ &amp;= \min \left(f(x^i) g(x^* | x^i), f(x^*) g(x^i | x^*) \right) \\ &amp;= f(x^*) g(x^i | x^*) \min \left(1, \frac{f(x^i) g(x^* | x^i)}{f(x^*) g(x^i | x^*)} \right) \\ &amp;= f(x^*) T(x^*, x^i) \end{aligned}\] <h2 id="references">References</h2> <ul> <li><a href="https://www2.cs.arizona.edu/~pachecoj/courses/csc535_fall20/lectures/mcmc.pdf">https://www2.cs.arizona.edu/~pachecoj/courses/csc535_fall20/lectures/mcmc.pdf</a></li> <li><a href="https://www.google.com/books/edition/Computational_Statistics/62OshZGXKq0C?hl=en">Computational Statistics</a></li> </ul>]]></content><author><name></name></author><category term="probability"/><category term="inversion"/><category term="math"/><summary type="html"><![CDATA[Getting organized like a Markov Chain]]></summary></entry><entry><title type="html">Sampling</title><link href="https://ayushinav.github.io/blog/2024/sampling/" rel="alternate" type="text/html" title="Sampling"/><published>2024-04-09T16:40:16+00:00</published><updated>2024-04-09T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2024/sampling</id><content type="html" xml:base="https://ayushinav.github.io/blog/2024/sampling/"><![CDATA[<h1 id="sampling">Sampling</h1> <h2 id="exact-sampling">Exact sampling</h2> <p>For most distributions, if we know the exact parametric form, we can get exact sampling from it. Most programming languages achieve this by generating random samples from a uniform distribution, then inverse mapping the cumulative distribution function to give a sample from the distribution.</p> <p>Therefore, for any continuous function \(F\) having the PDF \(f\),</p> \[X = F^{-1}(U) \implies X \sim f \; ; Y \sim \operatorname{Unif}(0,1)\] <p>Programming languages have their implementations to generate random numbers that have the same statistical property as the numbers sampled from a uniform distribution in \([0,1]\). We can understand the above more intuitively by imaging a CDF. A random number U sampled from \(\operatorname{Unif}(0,1)\) will be sampled on the y-axis of the CDF curve. More samples of \(X\) will be sampled from the distribution by \(X = F^{-1}(U)\) where the CDF is steeper, or in the region where the PDF peaks, eg., a narrow gaussian will rise more steeply compared to a broad one. Assuming both are centered around the same point, the narrow one will sample more points around the center.</p> <h2 id="rejection-sampling">Rejection sampling</h2> <p>Often, sampling from \(f(x)\) is not feasible but there maybe a bounding distribution \(g(x)\) such that</p> \[f(x) \le c g(x) \; ; c \ge 1 \quad \forall x\] <p>In such cases, where we know the bound of \(f(x)\) upto some proportionality constant, rejection sampling is employed. We sample from \(f(x)\) by</p> <ul> <li>Sample \(X \sim g(x)\)</li> <li>Sample \(U \sim \operatorname{Unif}[0,1]\)</li> <li>Accept \(X\) as being drawn from \(f(x)\) when \(\frac{f(X)}{c e(X)} \ge U \; \text{where} \; e(x) = c g(x)\)</li> </ul> <p>Rigorously, this works because:</p> \[\begin{aligned} P(X \le x | \frac{f(X)}{e(X)} \ge U) &amp;= P(X \le x | U \le \frac{f(X)}{e(X)}) \\ &amp;= \frac{P(X \le x , U \le \frac{f(X)}{e(X)})}{P(U \le \frac{f(X)}{e(X)})} \\ &amp;= \frac{P(U \le \frac{f(X)}{e(X)}, X \le x)}{P(U \le \frac{f(X)}{e(X)}, X \le \infty )} \\ \text{In above, } X \le \infty &amp; \text{ will not impose any constraint and allows us to see the steps more clearly} \\ \text{Now, noting that } P({X \le x}) &amp;= \int_0^x g(y)dy \text{ because we're sampling from } g(y) \\ &amp;= \frac{\int_0^{x} P(U \le \frac{f(X)}{e(X)}) g(y) dy}{\int_0^{\infty} P(U \le \frac{f(X)}{e(X)}) g(y) dy} \\ &amp;= \frac{\int_0^x \frac{f(y)}{e(y)} g(y) dy}{\int_0^{\infty} \frac{f(y)}{e(y)} g(y) dy} \\ \because P({U \le k}) = k; \; &amp; U \sim \operatorname{Unif}(0,1) \\ &amp;= \frac{\int_0^x \frac{f(y)}{c g(y)} g(y) dy}{\int_0^{\infty} \frac{f(y)}{c g(y)} g(y) dy} \\ &amp;= \frac{\frac{1}{c} \int_0^x f(y)}{\frac{1}{c} \int_0^{\infty} f(y)} \\ &amp;= \int_0^x f(y) dy \\ &amp;= P(X \le x) \end{aligned}\] <p>We, therefore, sample EXACTLY from \(f(x)\).</p> <h3 id="what-about-c">What about \(c\)…</h3> <p>The only thing we need to estimate now is \(c\). The only constraint we have is</p> \[f(x) \le c g(x) \; ; c \ge 1 \quad \forall x\] <p>It only seems easy that we choose a large value so that is easily satisfies \(f(x) \le c g(x)\). We, however, need to understand the effect of \(c\) on the acceptance probability.</p> <p>The acceptance probability is a marginal probability for all samples :</p> \[\begin{aligned} P(\frac{f(X)}{e(X)} \ge U , X) &amp;= % \sum_X P(\frac{f(X)}{e(X)} \ge U | X) P(X) \\ \mathrm{E}_{X \sim g}\left[P(\frac{f(X)}{e(X)} \ge U | X)\right] \\ &amp;= \mathrm{E}_{X \sim g}\left[\frac{f(X)}{e(X)}\right] \\ &amp;= \mathrm{E}_{X \sim g}\left[\frac{f(X)}{c g(X)}\right] \\ &amp;= \int \frac{f(X)}{c g(x)} g(x) dx \\ &amp;= \frac{1}{c} \end{aligned}\] <p>The only thing to note here is that</p> \[P(\frac{f(X)}{e(X)} \ge U | X) = \frac{f(x)}{e(x)}\] <p>Once we know the value of \(X\) than we can evaluate the above using the property of the uniform distribution.</p> <p>The \(c\), therefore, plays an important role and should be chosen as small as possible to accept maximum number of samples.</p> <h3 id="when-you-know-the-probability-distribution-upto-a-constant">When you know the probability distribution upto a constant</h3> <p>Rejection sampling is particularly useful if we know a distribution \(h(x)\) only upto an unknown constant, i.e., \(h(x) = K f(x) \implies f(x) = h(x)/K\), where \(f(x)\) can be easily computed.</p> <p>Such cases are mostly observed in Bayesian inference, where \(K\) is an intractable constant (integral of a certain distribution) and less than 1, therefore, \(f(x) \ge h(x)\) and is an envelope over \(h(x)\).</p> <p>We can then have \(e(x) = c g(x) \ge f(x)\) and follow similar steps, by sampling from \(g(x)\) and accepting if \(\frac{f(x)}{c g(x)} \ge U\). The constant \(1/K\) cancels out both in the numerator as well as the denominator and we sample exactly from \(f(x)\).</p> <p>The acceptance probability, however, changes as</p> \[\begin{aligned} P(\frac{f(X)}{e(X)} \ge U , X) &amp;= % \sum_X P(\frac{f(X)}{e(X)} \ge U | X) P(X) \\ \mathrm{E}_{X \sim g}\left[P(\frac{f(X)}{e(X)} \ge U | X)\right] \\ &amp;= \mathrm{E}_{X \sim g}\left[\frac{f(X)}{e(X)}\right] \\ &amp;= \mathrm{E}_{X \sim g}\left[\frac{f(X)}{c g(X)}\right] \\ &amp;= \int \frac{f(X)}{c g(x)} g(x) dx \\ &amp;= \int \frac{h(X)/ K}{c g(x)} g(x) dx \\ &amp;= \frac{1}{K c} \end{aligned}\] <p>We, therefore, have more samples rejected. In the above, it is important to note that \(\int f(x) dx \neq 1\) because \(f(x)\) is not a probability distribution, it is a scaled distribution of \(h(x)\), and \(\int f(x) dx = 1\), \(f(x)\) is more of a convinience function that can be computed.</p>]]></content><author><name></name></author><category term="probability"/><category term="math"/><summary type="html"><![CDATA[Sampling from distributions]]></summary></entry><entry><title type="html">Monte Carlo</title><link href="https://ayushinav.github.io/blog/2024/monte_carlo/" rel="alternate" type="text/html" title="Monte Carlo"/><published>2024-02-02T16:40:16+00:00</published><updated>2024-02-02T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2024/monte_carlo</id><content type="html" xml:base="https://ayushinav.github.io/blog/2024/monte_carlo/"><![CDATA[<h1 id="why-monte-carlo">Why Monte Carlo</h1> <p>More generally, the method is used to perform numerical integration. There exist various other methods for the task., eg. Trapezoid rule, Simpson’s rule, Runge-Kutta method of various orders, Guass quadrature and many more. These methods provide a convergence rate of \(\mathcal{O}(n^{-2})\) or better for \(n\) nodes. If we know something about the function, we can reduce the number of points and still get the desired accuracy, eg. if a function is known to be quadratic, we can get the exact integral from 3 nodes.</p> <p>While these methods may appear good so far, they do not scale well with higher dimensions. Since, these methods rely upon discretizing the space, the number of points increases exponentially with the number of dimensions. In a \(d\)-dimensional space, if we have \(n\) points in each dimension, the total number of points becomes \(n^d\). Monte Carlo method of integrating function is essentially mesh-free. It is performed by sampling random points from a certain distribution and evaluating the function at those points. This draws motivation from the Gauss Quadrature to integrate functions.</p> <p><strong>Brief intro to Gauss quadrature:</strong> Gauss quadrature is an efficient way to estimate the integral of a function. It provides better accuracy because unlike Trapezoid rule, Simpson’s rules, the node points are also free. Intuitively, it would make more sense to put more points in the region where function peaks to get better estimate.</p> <p>The method particularly integrates functions of the form \(\int_a^b f(x) w(x) dx\) where \(w(x)\) has properties of a density function. When evaluating \(\int_a^b f(x) dx\), we simply substitute a \(f^*(x) = f(x)/w(x)\) and then estimate \(\int_a^b f^*(x) w(x) dx\).</p> <p>The properties of \(w(x)\) determine the orthogonal polynomials, whose roots become the node points and the weights are estimated by a recursion relationship, getting to the form</p> \[\int_a^b f(x) w(x) dx = \sum_i^n A_i f(x_i)\] <hr/> <p>Something similar works in Monte Carlo integration. When integrating a function of the form \(\int_a^b f(x) w(x) dx\), we draw samples from the density function specified by \(w(x)\) and evaluate \(f(x)\) at these points, i.e.</p> \[\int_a^b f(x) w(x) dx = \sum_i f(x_i) \; , \; x \sim w(x)\] <p>The above has its foundations in the law of large numbers. When calculating mean of a distribution, we take the expectation:</p> \[\mu = \frac{1}{n}\sum_i^n x_i ; \; x_i \sim w(x) \xrightarrow[]{n \rightarrow \infty} \int_{\Omega} w(x) dx\] <p>and similarly, for the mean of the function on some distribution:</p> \[\mu(f(\cdot)) = \frac{1}{n}\sum_i^n f(x_i) ; \; x_i \sim w(x) \xrightarrow[]{n \rightarrow \infty} \int_{\Omega} f(x) w(x) dx\] <p>The above is also written as:</p> \[\begin{align*} \mathbf{E}_{x \sim w(x)}[f(x)] &amp; = \sum_i f(x_i) \; ; x_i \sim w(x) \\ &amp; = \int w(x) f(x) dx \end{align*}\] <p>Until now, we’d assumed that sampling from \(w(x)\) is easy. This might be true for certain families of distribution, but not always. The <a href="../../../2024/sampling/">Sampling</a> provides dives into how distributions are sampled.</p>]]></content><author><name></name></author><category term="probability"/><category term="math"/><summary type="html"><![CDATA[Because basics are important]]></summary></entry><entry><title type="html">FEM for 1D magnetotelluric modeling</title><link href="https://ayushinav.github.io/blog/2023/fem/" rel="alternate" type="text/html" title="FEM for 1D magnetotelluric modeling"/><published>2023-12-03T16:40:16+00:00</published><updated>2023-12-03T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2023/fem</id><content type="html" xml:base="https://ayushinav.github.io/blog/2023/fem/"><![CDATA[<h1 id="introduction">Introduction</h1> <h2 id="maxwells-equations">Maxwell’s equations</h2> <p>The theory for understanding the behaviour of electromagnetic waves often begin with their behaviour in vacuum, often governed by a set of four equations called Maxwell’s equations: <br/> \begin{equation} \nabla \cdot E= -\rho_e/\epsilon_0 \label{Coulomb} \end{equation} \begin{equation} \nabla \times E= -\mu_0 \partial_t H \label{Faraday} \end{equation} \begin{equation} \nabla \cdot H= 0 \label{Gauss} \end{equation} \begin{equation} \nabla \times H= J+ \epsilon_0\partial_tE \label{Ampere} \end{equation}<br/> where \(E\) is the electric field, \(H\) is the magnetic field, \(M_s\) is the magnetic field source, \(\rho\) is resistivity, \(\rho_e\) is the charge density, \(J\) is current density, \(\mu_0\) is the magnetic permeability of the free space, and \(\epsilon_0\) is the electrical permittivity of the free space. In the above set of equations, eqn. \eqref{Coulomb} is known as Coulomb’s law of Gauss’ law for electric fields, which describes the electric field generated by a charge distribution. However, in a medium, the Maxwell equations are also accompanied by the constitutive relations. In our case, while investigating the behaviour of electromagnetic fields inside the earth, only one relationship makes an innegligible difference: \(\begin{equation} J= \sigma E \label{Ohm} \end{equation}\\\)</p> <p>The above is referred as the Ohm’s law, which states that the electric current density \(J\) in a medium is directly proportional to the electric field \(E\) across it with the constant of proportiaonality being the electrical conductivity of the material \(\sigma\). Substituting this in eqn \eqref{Ampere}, we get \begin{equation} \nabla \times H= \sigma E+ \epsilon_0\partial_tE \label{Ampere_Ohm} \end{equation}<br/> Beginning our derivation of the 1D MT partial diffferential equation, we take the curl of \eqref{Faraday},</p> <p>\begin{equation} \nabla \times \nabla \times E= -\mu_0 \partial_t \nabla \times H \end{equation}</p> <p>Substituting equation \eqref{Ampere} and making use of \eqref{Ohm}, we get</p> \[\nabla \times \nabla \times E= -\mu_0 \sigma \partial_t E - \epsilon_0 \partial_t^2E\] <p>Taking advantage of the vector identity \(\nabla \times \nabla \times A= \nabla(\nabla \cdot A)- \nabla^2 A\), this simplifies into</p> \[\nabla(\nabla \cdot E)- \nabla^2 E= -\mu_0 \sigma \partial_t E - \epsilon_0 \partial_t^2E\] <p>Now substituting \eqref{Coulomb} in the above, we get</p> \[\nabla(\rho/\epsilon_0)- \nabla^2 E= -\mu_0 \sigma \partial_t E - \epsilon_0 \partial_t^2E\] <p>Noting that charge density does not change a lot in time, the above simplifies to \begin{equation} - \nabla^2 E= -\mu_0 \sigma \partial_t E - \epsilon_0 \partial_t^2E<br/> \label{pde_E} \end{equation} Taking the Fourier transform of the above with respect to \(t\), we have</p> \[- \nabla^2 E= -i \omega \mu_0 \sigma E + \omega^2 \epsilon_0 E\] <p>For the order of frequencies used in the MT method, the second term in the above expression is negligible compared to the first one. This is called the quasi-static approximation. Using this relation, we have</p> \[- \nabla^2 E= -i \omega \mu_0 \sigma E\] \[\nabla^2 E -i \omega \mu_0 \sigma E = 0\] <p>In 1D, this is equivalent to</p> \[\begin{align} \notag &amp; \frac{\partial^2 E}{\partial^2 z}- i \omega \mu \sigma E =0 \\ \notag &amp; \texttt{For} \quad k^2= i \omega \mu \sigma \\ &amp; \frac{\partial^2 E}{\partial^2 z}- k^2 E=0 \label{E2k} \end{align}\] <h1 id="methodology">Methodology</h1> <h2 id="getting-to-the-linear-system">Getting to the linear system</h2> <p>The idea of the finite element method is to approximate a function in some basis space. To implement the scheme, we need to write the eqn \ref{E2k} in its weak form. In order to do that, we multiply both sides of the equation by any function \(W(z)\), called the weight function.</p> \[\begin{align} \notag &amp; \frac{\partial^2 E}{\partial^2 z} W- k^2 E W=0 \\ \notag &amp; \texttt{Integrating bothe sides wrt} \quad z \\ \notag &amp; \int_{\Omega} \frac{\partial^2 E}{\partial^2 z} W dz- \int_{\Omega} k^2 E W dz=0 \\ \notag &amp; \texttt{where} \; \Omega \; \texttt{is the computational domain, spanning the model space.} \\ \notag &amp; \texttt{Integrating the first term by parts, we have} \\ \notag &amp; - \int_{\Omega} \frac{\partial E}{\partial z} \frac{\partial W}{\partial z} dz+ \bigg|W \frac{\partial E}{\partial z}\bigg|_{d \Omega}- \int_{\Omega} k^2 E W dz=0 \end{align}\] <p>The second term in the above equation \(\bigg|W \frac{\partial E}{\partial z}\bigg|_{d \Omega}\) is equivalent to \(\bigg|W \frac{\partial E}{\partial z}\bigg|_{0}^Z\), that is, an expression evaluated at the end points. These end points are used to apply the boundary conditions. In the above conditions, we set \(W\)= 0 at the boundaries. This means that the boundary condition (Neumann or Dirichlet) is strictly imposed which we will show later in detail and therefore the residue is zero. This allows us to apply the Dirichlet boundary conditions, which is what we require for the MT problems. This also makes the second term equal to 0 and we have \begin{equation} \int_{\Omega} \frac{\partial E}{\partial z} \frac{\partial W}{\partial z} dz+ \int_{\Omega} k^2 E W dz=0 \label{E2} \end{equation} Before we move on, we need to understand and implement the first line of this section, that is, express the \(E\) field using some known basis functions, say \(\phi(z)\). We can then write \begin{equation} E= \sum_i \alpha_i \phi_i + \phi_0 \label{E_hat} \end{equation} where \(\phi_i(z)\) represents the basis function in the \(i^{th}\) element scald by a factor \(\alpha_i\). For our implementation, we use the linear basis functions, more popularly called as the hat functions. <a href="#hat">This</a> shows the hat functions for a grid-space defined between 0 and 1. We use 6 hat functions in the figure, each centered on its own node, eg. the function \(\phi_1(z)\) is centered at the node 1 at \(z= 0.2\). It starts with a positive slope at \(z=0\), peaks at \(z=0.2\) and then slopes down until \(z=0.4\).</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/fem/hat-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/fem/hat-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/fem/hat-1400.webp"/> <img src="/assets/fem/hat.png" class="img-fluid rounded z-depth-1" width="450" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption">Hat functions for a sample gridspace [0,1]</figcaption> </figure> <p>Using eqn \ref{E_hat} in \ref{E2}, we have \begin{equation} \int_{\Omega} \sum_i \alpha_i \phi_i’ \frac{\partial W}{\partial z} dz+ \int_{\Omega} k^2 \sum_i \alpha_i \phi_i W dz=0 \label{E3} \end{equation} The finite element method also tries to approximate the weight function by expressing it in terms of some basis functions, much like what we have for \(E\) in eqn \ref{E2}. In principle, we can choose any basis function to approximate \(W\) but the most common and efficient way is by using Galerkin’s method, that is, by using the same basis used for \(E\) can be used for \(W\). We then have \begin{equation} W= \sum_j \beta_j \phi_j \label{What} \end{equation} Pulling out the \(j^{th}\) function from the above and plugging into eqn \ref{E3}, we have</p> \[\begin{align} \notag &amp; \int_{\Omega} \sum_i \alpha_i \phi_i' \beta_j \phi_j' dz+ \int_{\Omega} k^2 \sum_i \alpha_i \phi_i \beta_j \phi_j dz=0 \\ \notag &amp; \beta_j \; \texttt{being a scalar constant} \\ &amp; \int_{\Omega} \sum_i \alpha_i \phi_i(z)' \phi_j(z)' dz+ \int_{\Omega} k^2 \sum_i \alpha_i \phi_i(z) \phi_j(z) dz=0 \label{E4} \end{align}\] <p>Plugging different values \(j\), we can obtain the system of equations to be solve for \(\alpha_i\)’s. Let’s say we have the grid defined for 5 elements, like <a href="#hat">here</a>. The eqn \ref{E4} then looks like \(\begin{align} \notag &amp; (j=0) \\ \notag &amp; \int_0^1 \alpha_0 \phi_0' \phi_0'+ \alpha_1 \phi_1' \phi_0'+ \dots \alpha_5 \phi_5' \phi_0' dz+ \int_0^1 k^2 \alpha_0 \phi_0 \phi_0+ \alpha_1 \phi_1 \phi_0+ \dots \alpha_5 \phi_5 \phi_0 dz=0 \\ \notag &amp; (j=1) \\ \notag &amp; \int_0^1 \alpha_0 \phi_0' \phi_1'+ \alpha_1 \phi_1' \phi_1'+ \dots \alpha_5 \phi_5' \phi_1' dz+ \int_0^1 k^2 \alpha_0 \phi_0 \phi_1+ \alpha_1 \phi_1 \phi_1+ \dots \alpha_5 \phi_5 \phi_1 dz=0 \\ \notag \vdots \\ \notag &amp; (j=5) \\ \notag &amp; \int_0^1 \alpha_0 \phi_0' \phi_5'+ \alpha_1 \phi_1' \phi_5'+ \dots \alpha_5 \phi_5' \phi_5' dz+ \int_0^1 k^2 \alpha_0 \phi_0 \phi_5+ \alpha_1 \phi_1 \phi_5+ \dots \alpha_5 \phi_5 \phi_5 dz=0 \\ \end{align}\)</p> <p>Before, we attempt to get the linear system of equations, it would be helpful for notation purposes if we define</p> \[\begin{align*} A_{ji}= \int_0^1 \phi_i'(z) \phi_j'(z) dz \\ B_{ji}= \int_0^1 k^2 \phi_i(z) \phi_j(z) dz \\ \end{align*}\] <p>We then have</p> \[\begin{equation}\label{E6} \begin{split} &amp; (j=0) \\ &amp; [ A_{00} \alpha_0+ A_{01} \alpha_1+ \dots A_{05} \alpha_5]+ [B_{00} \alpha_0+ B_{01} \alpha_1+ \dots B_{05} \alpha_5]= 0 \\ &amp; (j=1) \\ &amp; [ A_{10} \alpha_0+ A_{11} \alpha_1+ \dots A_{15} \alpha_5]+ [B_{10} \alpha_0+ B_{11} \alpha_1+ \dots B_{15} \alpha_5]= 0 \\ \dots \\ &amp; (j=5) \\ &amp; [ A_{50} \alpha_0+ A_{51} \alpha_1+ \dots A_{55} \alpha_5]+ [B_{50} \alpha_0+ B_{51} \alpha_1+ \dots B_{55} \alpha_5]= 0 \end{split} \end{equation}\] <p>With \(A_{ij}\) as the elements of the matrix \(A\) and \(B_{ij}\) as the elements of the matrix \(B\), and \(\alpha\) as the vector of \(\alpha_i\)’s, we can write the above as:</p> \[[A+B]\alpha = 0\] <h2 id="getting-elements-of-the-linear-system">Getting elements of the linear system</h2> <p>While the eqn \eqref{E6} seems to involve a lot of calculations, in reality it is very easy. The following figure shows the functions for \(\phi_0, \phi_1, \phi_4 and \phi_5\).</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/fem/hat2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/fem/hat2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/fem/hat2-1400.webp"/> <img src="/assets/fem/hat2.png" class="img-fluid rounded z-depth-1" width="450" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Before evaluating the explicit integrals, it is noteworthy that the integrals will be non-zero only when both the functions in a region are non-zero. If either of them is zero, the product vanishes.</p> \[\begin{align*} A_{10} &amp;= \int_0^1 \phi_0'(z) \phi_1'(z) dz \\ &amp;= \int_0^{\Delta x} \phi_0'(z) \phi_1'(z) dz \quad \texttt{(The product vanishes everywhere else)}\\ &amp;= \phi_0'(z) \phi_1'(z) \int_0^{\Delta x} dz= \Delta x \times \frac{1}{\Delta x} \times \frac{-1}{\Delta x} = \frac{-1}{\Delta x}\\ A_{11} &amp;= \int_0^1 \phi_0'(z) \phi_0'(z) dz \\ &amp;= \int_0^{2 \Delta x} \phi_1'(z)^2 dz \quad \texttt{(The product vanishes everywhere else)}\\ &amp;= \phi_1'(z)^2 \int_0^{2 \Delta x} dz= \Delta x \times \frac{1}{(\Delta x)^2} = \frac{1}{\Delta x}\\ A_{51} &amp;= \int_0^1 \phi_1'(z) \phi_5'(z) dz \\ &amp;= 0 \quad \texttt{(The product vanishes everywhere)}\\ \end{align*}\] <p>Similarly, we have for \(B\) (note that \(k^2\) is constant in an element) \(\begin{align*} B_{10} &amp;= \int_0^1 k^2 \phi_0(z) \phi_1(z) dz \\ &amp;= \int_0^{\Delta x} k^2 \phi_0(z) \phi_1(z) dz \quad \texttt{(The product vanishes everywhere else)}\\ &amp;= k^2 \int_0^{\Delta x} \left(1- \frac{x}{\Delta x}\right) \left( \frac{x-0}{\Delta x} \right)dz= k^2 \bigg| \frac{x^2}{2\Delta x}- \frac{x^3}{3(\Delta x)^2}\bigg|_0^{\Delta x}= \frac{k^2 \Delta x}{6}\\ B_{11} &amp;= \int_0^1 k^2 \phi_1(z) \phi_1(z) dz \\ &amp;= \int_0^{\Delta x} k^2 \phi_1(z)^2 dz \quad \texttt{(The product vanishes everywhere else)}\\ &amp;= k^2 \int_0^{\Delta x} \left(\frac{x-0}{\Delta x}\right)^2 = k^2 \bigg| \frac{(x-0)^3}{3(\Delta x)^2}\bigg|_0^{\Delta x}= \frac{k^2 \Delta x}{3}\\ B_{51} &amp;= \int_0^1 \phi_1(z) \phi_5(z) dz \\ &amp;= 0 \quad \texttt{(The product vanishes everywhere)}\\ \end{align*}\)</p> <p>When we obtain the above for all elements, the matrices look like</p> \[\begin{align*} A= &amp; \left[ \begin{array}{cccccc} \frac{1}{\Delta x} &amp; \frac{-1}{\Delta x} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ \frac{-1}{\Delta x} &amp; \frac{2}{\Delta x} &amp; \frac{-1}{\Delta x} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp;\frac{-1}{\Delta x} &amp; \frac{2}{\Delta x} &amp; \frac{-1}{\Delta x} &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; \frac{-1}{\Delta x} &amp; \frac{2}{\Delta x} &amp; \frac{-1}{\Delta x} &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{-1}{\Delta x} &amp; \frac{2}{\Delta x} &amp; \frac{-1}{\Delta x}\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \frac{-1}{\Delta x} &amp; \frac{1}{\Delta x}\ \end{array} \right] \\ \\ B= &amp; \left[ \begin{array}{cccccc} \frac{k^2 \Delta x}{3} &amp; \frac{k^2 \Delta x}{6} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ \frac{k^2 \Delta x}{6} &amp; \frac{2 k^2 \Delta x}{3} &amp; \frac{k^2 \Delta x}{6} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \frac{k^2 \Delta x}{6} &amp; \frac{2 k^2 \Delta x}{3} &amp; \frac{k^2 \Delta x}{6} &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; \frac{k^2 \Delta x}{6} &amp; \frac{2 k^2 \Delta x}{3} &amp; \frac{k^2 \Delta x}{6} &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{k^2 \Delta x}{6} &amp; \frac{2 k^2 \Delta x}{3} &amp; \frac{k^2 \Delta x}{6}\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \frac{k^2 \Delta x}{6} &amp; \frac{k^2 \Delta x}{3}\ \end{array} \right] \end{align*}\] <p>For non-uniform grid spacing, the above modifies as</p> \[\begin{align*} A= &amp; \left[ \begin{array}{cccccc} \frac{1}{\Delta x_1} &amp; \frac{-1}{\Delta x_1} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ \frac{-1}{\Delta x_1} &amp; \frac{1}{\Delta x_1}+ \frac{1}{\Delta x_2} &amp; \frac{-1}{\Delta x_2} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \frac{-1}{\Delta x_2} &amp; \frac{1}{\Delta x_2}+ \frac{1}{\Delta x_3} &amp; \frac{-1}{\Delta x_3} &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; \frac{-1}{\Delta x_3} &amp; \frac{1}{\Delta x_3}+ \frac{1}{\Delta x_4} &amp; \frac{-1}{\Delta x_4} &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{-1}{\Delta x_4} &amp; \frac{1}{\Delta x_4}+ \frac{1}{\Delta x_5} &amp; \frac{-1}{\Delta x_5}\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \frac{-1}{\Delta x_5} &amp; \frac{1}{\Delta x_5}\ \end{array} \right] \\ \\ B= &amp; \left[ \begin{array}{cccccc} \frac{k^2 \Delta x_1}{3} &amp; \frac{k^2 \Delta x_1}{6} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ \frac{k^2 \Delta x_1}{6} &amp; \frac{k^2 \Delta x_1}{3}+ \frac{k^2 \Delta x_2}{3} &amp; \frac{k^2 \Delta x_2}{6} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \frac{k^2 \Delta x_2}{6} &amp; \frac{k^2 \Delta x_2}{3}+ \frac{k^2 \Delta x_3}{3} &amp; \frac{k^2 \Delta x_3}{6} &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; \frac{k^2 \Delta x_3}{6} &amp; \frac{k^2 \Delta x_3}{3}+ \frac{k^2 \Delta x_4}{3} &amp; \frac{k^2 \Delta x_4}{6} &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{k^2 \Delta x_4}{6} &amp; \frac{k^2 \Delta x_4}{3}+ \frac{k^2 \Delta x_5}{3} &amp; \frac{k^2 \Delta x_2}{5}\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \frac{k^2 \Delta x_5}{6} &amp; \frac{k^2 \Delta x_5}{3}\ \end{array} \right] \end{align*}\] <h2 id="boundary-conditions">Boundary Conditions</h2> <p>For 1D MT forward modeling, one can either put the a form of source field into the Maxwell’s equations. This, however, can be simplified for the 1D case, where the \(E\) field is typically set to 1 (or any constant) on the surface and noting the attenuating nature of the fields, it is safe to assume that \(E=0\) at the deepest point being modeled. To ensure that this does happen, we need to make the computational domain large enough, which is usually set to a few skin depths corresponding to the largest resistivity for a given frequency.</p> <h2 id="discretization">Discretization</h2> <p>One of the advantages of using finite element is that we can have non-uniform grid sizes. This allows us to have larger grid sizes whenever the structure is homogeneous and do a finer sampling whenever we come across structures/ inhomogeneities. In our case, we tested on a uniform grid spacing to draw comparisons in the matrix structure with finite differences. We then do a non-uniform sampling to show how finite element can be computationally efficient compared to the finite differences. Basing on the idea that we should have finer grid spacing near boundaries, we had the spacing that increase in arithematic progression starting from the edges until the center and then decreasing in the same order until the other edge. We apply this scheme for all the layers. This is schematically shown <a href="fe_nodes">here</a>.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/fem/spacing-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/fem/spacing-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/fem/spacing-1400.webp"/> <img src="/assets/fem/spacing.png" class="img-fluid rounded z-depth-1" width="450" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption">Nodes for discretization of the model space</figcaption> </figure> <p>Note that the above does not plot the depth on a log-scale to show the spacing in between the points, which otherwise gets skewed by the log function. Also, note that one can use any other discretization scheme that fits well with the objective. The one chosen here makes intuitive sense and may not be the best one but is a good one, as will also be shown in the next section.</p> <p>Since the last layer is treated as an infinite thickness layer, which is not computationally feasible, the common practice is to have its bottom depth extend until a few maximum skin depths for a given frequency. While this post contains the numerical framework, the codes can be accessed <a href="https://github.com/ayushinav/MT_1D">here</a>.</p> <h1 id="computational-comparison-to-finite-difference">Computational Comparison to Finite Difference</h1> <h2 id="matrix-structure">Matrix structure</h2> <p>For comparison with the finite differences, we make the grid size uniform for finite elements. The matrix to be inverted in finite element case is</p> \[\begin{align*} K= &amp; A+ B= \\ &amp; \left[ \begin{array}{cccccc} \frac{1}{\Delta x}+ \frac{k^2 \Delta x}{3} &amp; \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; \frac{2}{\Delta x}+ \frac{2 k^2 \Delta x}{3} &amp; \frac{-1}{\Delta x+ \frac{k^2 \Delta x}{6}} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp;\frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; \frac{2}{\Delta x}+ \frac{2 k^2 \Delta x}{3} &amp; \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; \frac{2}{\Delta x}+ \frac{2 k^2 \Delta x}{3} &amp; \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; \frac{2}{\Delta x}+ \frac{2 k^2 \Delta x}{3} &amp; \frac{-1}{\Delta x+ \frac{k^2 \Delta x}{6}}\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \frac{-1}{\Delta x}+ \frac{k^2 \Delta x}{6} &amp; \frac{1}{\Delta x}+ \frac{k^2 \Delta x}{3}\ \end{array} \right] \end{align*}\] <p>In finite differences, the matrix to be inverted had the form:</p> \[\begin{align*} K= \\ &amp; \left[ \begin{array}{cccccc} \frac{-1}{(\Delta x)^2} &amp; -k^2+ \frac{1}{\Delta x}^2 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ \frac{1}{\Delta x} &amp; -k^2 - \frac{2}{(\Delta x)^2} &amp; \frac{1}{(\Delta x)^2} &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; \frac{1}{\Delta x} &amp; -k^2 - \frac{2}{(\Delta x)^2} &amp; \frac{1}{(\Delta x)^2} &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; \frac{1}{\Delta x} &amp; -k^2 - \frac{2}{(\Delta x)^2} &amp; \frac{1}{(\Delta x)^2} &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; \frac{1}{\Delta x} &amp; -k^2 - \frac{2}{(\Delta x)^2} &amp; \frac{1}{(\Delta x)^2}\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; -k^2+ \frac{1}{\Delta x}^2 &amp; \frac{-1}{(\Delta x)^2}\\ \end{array} \right] \end{align*}\] <p>The matrices look very similar, with both of them being tridiagonal. It is interesting to see that in finite element, the \(k^2\) term is also present in the non-diagonal terms while it is only present in the diagonal elements in the finite difference case.</p> <h2 id="error-analysis">Error analysis</h2> <p>Due to its flexibility, we expect finite element to be computationally efficient and/or providing better accuracy. We do a quantitative analysis to show how much the the difference between the two schemes is. We first define the error metric as:</p> \[\operatorname{err}(\rho_a)= \frac{1}{N} \sum_i \frac{|\rho_{analytical}^i- \rho_{numerical}^i|}{|\rho_{analytical}^i|} \times 100\] \[\operatorname{err}(\phi)= \frac{1}{N} \sum_i \frac{|\phi_{analytical}^i- \phi_{numerical}^i|}{|\phi_{analytical}^i|} \times 100\] <p><br/></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/fem/appres_err-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/fem/appres_err-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/fem/appres_err-1400.webp"/> <img src="/assets/fem/appres_err.png" class="img-fluid rounded z-depth-1" width="650" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><br/></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/fem/phase_err-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/fem/phase_err-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/fem/phase_err-1400.webp"/> <img src="/assets/fem/phase_err.png" class="img-fluid rounded z-depth-1" width="650" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>As can be evidently seen <a href="#err_appres">here</a> and <a href="#err_phase">here</a>, the finite element accumulates less errors compared to the finite difference method. Though the bigger highlight is that the finite element provides a better accuracy when compared to the finite element with more than an order of magnitude less number of points compared to the finite difference.</p> <h2 id="resolution-loss-in-discretization">Resolution loss in discretization</h2> <p>In finite differences, we are almost always constrained to have a uniform spacing. This leads us to choose a certain grid spacing for the whole space. This is usually chosen to be a small percentage of the minimum skin depth for a given frequency. This invariably leads to a loss in resolution because the layers may not necessarily end at a certain multiple of the grid spacing, as shown <a href="#disc">here</a></p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/fem/discretization-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/fem/discretization-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/fem/discretization-1400.webp"/> <img src="/assets/fem/discretization.png" class="img-fluid rounded z-depth-1" width="550" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture><figcaption class="caption">Errors in model due to different discretization</figcaption> </figure> <p>In finite element, since we deal with the element spaces, we have the conductivity value known in all the element spaces. These element spaces are obviously homoegeneous and heterogeneities are captured by the node points. This allows us to get to the exact boundary structure.</p> <p>The idea can further be propagated to multiple dimensions, wherein we can reduce the difference the resolution loss because of the discretization. As a last note, we realize that this is not a huge difference that can error the forward model for MT very much, especially in 1D, but is definitely worth noting and can be significant when moving on to 2D and 3D.</p> <h1 id="conclusion">Conclusion</h1> <p>From the discussion so far, one can safely say that the finite element is more challenging to implement compared to the finite difference scheme. Since it allows the user to get flexible with the descritization, it needs to be implemented in the right way. The advantages, however, outweigh, the disadvantages. We can get a closer approximation to the resistivity distribution being modeled, which implies less resolution loss. The main highlight of finite element is that it allows us to use less number of grid points. Since both finite element and finite difference have the same tridiagonal matrix structure, the computational cost for inverting both the matrices will be the same, implying finite element will be orders of magnitude faster than the finite difference, as can be observed in the figures in the <a href="#error-analysis">Error analysis</a> section, where the finite element obtains the same accuracy in 10 times or even 100 times less node points.</p> <p>These advantages become more pronounced in 2D and 3D, where the number of node points increase dramatically, and also allow us to include topography into the model. Therefore, the use of finite elements over finite differences is encouraged.</p> <h1 id="acknowledgement">Acknowledgement</h1> <ul> <li>Thanks a lot to <a href="https://donglaiyang.org/">Dong Lai Yang</a> for starting me with FE methods.</li> <li>Class notes of Georgia Tech EAS 8803 Electromagnetic Methods course</li> <li><a href="https://ocw.mit.edu/courses/18-085-computational-science-and-engineering-i-fall-2008/video_galleries/video-lectures/">MIT 18.085 Computational Science and Engineering I</a></li> </ul>]]></content><author><name></name></author><category term="modeling"/><category term="geophysics"/><category term="math"/><category term="code"/><summary type="html"><![CDATA[Finite element modeling for 1D magnetotelluric response]]></summary></entry><entry><title type="html">Variational Inference</title><link href="https://ayushinav.github.io/blog/2023/variational-inference/" rel="alternate" type="text/html" title="Variational Inference"/><published>2023-11-09T16:40:16+00:00</published><updated>2023-11-09T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2023/variational-inference</id><content type="html" xml:base="https://ayushinav.github.io/blog/2023/variational-inference/"><![CDATA[<h2 id="problem-statement">Problem statement</h2> <p>In geophysical inversion involving uncertainty quantification, we want to calculate the posterior \(p(m|d)\), where \(m\) are the model parameters we want to invert for and \(d\) are the observed data. Given the <em>a priori</em> distribution \(p(m)\) and the likelihood function \(p(d|m)\), the bayesian formulation is</p> \[p(m|d) \propto p(d|m) p(d)\] <p>An obvious candidate to the above problem is MCMC, which has asymptotic convergence guarantees. This however requires a large number of samples. Variational inference turns this inference problem into am optimization one.</p> <h1 id="theory-of-variational-inference">Theory of variational inference</h1> <p>Variational Inference approximates the posterior \(p(m|d)\) with a distribution \(q(m)\), parameterized on, say \(\phi\). Note that \(q(m)\) is still conditioned on \(d\). One would be \(q(m) = \mathcal{N}(\mu(d), \sigma(d)^2)\), where \(\mu\) and \(\sigma\) are the outputs from a network with \(d\) as input and parameterized on \(\phi\). We want \(q\) to be as similar to \(p(m|d)\). In other words, we want the KL divergence \(KL(q(m)|| p(m|d))\) between the two to be as small as possible:</p> \[\begin{aligned} KL(q(m|d)|| p(m|d)) &amp;= \mathbb{E}_{m \sim q(m|d)}\left[\log \frac{q(m|d)}{p(m|d)}\right] \\ &amp;= \mathbb{E}_{m \sim q(m|d)}\left[\log q(m|d)\right]- \mathbb{E}_{m \sim q(m)}\left[\log p(d| m)\right] - \mathbb{E}_{m \sim q(m)} \left[\log p(m)\right] + \mathbb{E}_{m \sim q(m)}\left[\log p(d)\right] \\ &amp;= \mathbb{E}_{m \sim q(m|d)}\left[\log q(m|d)\right]- \mathbb{E}_{m \sim q(m)}\left[\log p(d| m)\right] - \mathbb{E}_{m \sim q(m)} \left[\log p(m)\right] + \log p(m) \\ &amp; (\log p(m) \text{ is marginal and independent of sampling } m) \end{aligned}\] <p>The first three terms on the right hand side constitute the Evidence Lower Bound, or ELBO, defined as:</p> \[\begin{aligned} &amp; \operatorname{ELBO}(q) = \mathbb{E}_{m \sim q(m|d)}\left[\log p(m, d)\right] + \mathbb{E}_{m \sim q(m)}\left[\log p(m)\right] - \mathbb{E}_{m \sim q(m)}\left[\log q(m)\right] \\ \implies &amp; KL(q(m|d)|| p(m|d)) + \operatorname{ELBO}(q) = \log p(m) = \text{Constant} \end{aligned}\] <p>Therefore, maximizing ELBO minimizes the KL divergence. Minimizing ELBO can be done in the following steps:</p> <ul> <li>Sample \(d_i \sim p(d)\)</li> <li> <table> <tbody> <tr> <td>Get \(ELBO(q)\) by sampling $$m \sim q(m</td> <td>d)$$</td> </tr> </tbody> </table> </li> <li>Calculate \(\nabla_{\phi} \operatorname{ELBO}(q)\)</li> <li>Update \(\phi\) using gradient ascent</li> </ul> <h2 id="going-beyond">Going beyond</h2> <p>The theory of variational inference was mostly developed to obtain a parameteric distribution of the observed data variable \(d\) and assuming some latent variable \(m\). The marginal distribution is</p> \[p(d) = \int p(d|m) p(m) dm\] <p>In this case, we do not know what \(p(d|m)\) looks like, and let’s say it’s parameterized on \(\theta\). Let’s have \(q(m)\) again but this time it is to be used as a proposal distribution. For any sample \(d_i\), estimating the likelihood takes the form</p> \[\begin{aligned} \log p_{\theta}(d_i) &amp;= \log \int p_{\theta}(d_i|m)p(m)dm \\ &amp; \text{For any probabilty } q(m) \text { we have}\\ &amp;= \log \int \frac{p_{\theta}(d_i|z)p(m) }{q(m)} q(m)dm \\ &amp;= \log \mathbb{E}_{m \sim q(m)} \left[ \frac{p_{\theta}(d_i|m)p(m)}{q(m)}\right] \\ &amp; \text{Using Jensen's inequality} \\ &amp; \ge \mathbb{E}_{m \sim q(m)} \left[\log \frac{p_{\theta}(d_i|m)p(m)}{q(m)}\right] \\ &amp;= \mathbb{E}_{m \sim q(m)} \left[\log \frac{p_{\theta}(d_i|m)p(m)}{q(m)}\right] \\ &amp;= \mathbb{E}_{m \sim q(m)} \left[\log p_{\theta}(d_i|m)\right] + \mathbb{E}_{m \sim q(m)} \left[p(m)\right] - \mathbb{E}_{m \sim q(m)} \left[\log q(m) \right] \\ &amp;= ELBO(q) \end{aligned}\] <p>THus, the same ELBO becomes a lower bound to the marginal distribution of the observed variable. We now have to optimize with respect to \(\theta\), and minimizing ELBO has one more step:</p> <ul> <li>Sample \(d_i \sim p(d)\)</li> <li> <table> <tbody> <tr> <td>Get \(ELBO(q)\) by sampling $$m \sim q(m</td> <td>d)$$</td> </tr> </tbody> </table> </li> <li>Calculate \(\nabla_{\phi} \operatorname{ELBO}(q)\)</li> <li>Update \(\phi\) using gradient ascent</li> <li>Calculate \(\nabla_{\theta} \operatorname{ELBO}(q)\)</li> <li>Update \(\theta\) using gradient ascent</li> </ul> <h2 id="nabla_theta-operatornameelboq">\(\nabla_\theta \operatorname{ELBO}(q)\)</h2> <p>While all the steps looked fairly simple until now, there are a few nitty gritties. For a sample</p> <ul> <li>Sample \(d_i \sim p(d)\) \(d_i \sim p(d)\), we pass it throught the network to obtain \(q_\phi(m|d)\), eg., the network outputs the mean and variance of a normal distribution. Before any optimization, \(\phi\) is initialized in any way.</li> <li> <table> <tbody> <tr> <td>Get \(ELBO(q)\) by sampling $$m \sim q(m</td> <td>d)$$</td> </tr> <tr> <td>Sampling a few samples from $$q(m</td> <td>d)$$, the expectaion can be estimated.</td> </tr> </tbody> </table> </li> <li>Calculate \(\nabla_{\phi} \operatorname{ELBO}(q)\)</li> <li>Update \(\phi\) using gradient ascent</li> <li>Calculate \(\nabla_{\theta} \operatorname{ELBO}(q)\) We note that only the first term here is dependent on \(\theta\). \(p(m)\) is the <em>a priori</em> distribution of \(m\) and \(q(m|d)\) is parameterized on \(\phi\). For one sample, say \(m^*\), we pass it through the network to obtain the distribution \(p_\theta(d|m)\), we can easily differentiate through \(\theta\), using backpropagation.</li> <li>Update \(\theta\) using gradient ascent</li> </ul> <h2 id="nabla_phi-operatornameelboq">\(\nabla_\phi \operatorname{ELBO}(q)\)</h2> <p>Most of the steps are similar as above until we get to the point where we have to calculate \(\nabla_\phi \operatorname{ELBO}(q)\). The first thing we notice is we have to differentiate through the sampling process. To compute this, we make use of the reparameterization trick. This means we assume another variable \(\tilde{m}\) such that we can write</p> \[m \sim q_\phi(m) \Longleftrightarrow m = g_{\phi}(\tilde{m}) \quad \text{where} \quad \tilde{m} \sim h(\tilde{m})\] <p>This is better understood via an example. Let \(q(m)\) be \(\mathcal{N}(\mu, \sigma^2)\), then defining \(\tilde{m} \sim \mathcal{N}(0, 1)\)</p> \[m \sim \mathcal{N}(\mu, \sigma^2) \Longleftrightarrow m = \mu + \sigma \tilde{m} \quad \text{where} \quad \tilde{m} \sim \mathcal{N}(0, 1)\] <p>This way, we can sample from \(\tilde{m}\) to get the samples from the same distribution as \(m\). We, therefore, sample \(\tilde{m}\) and not \(m\). The ELBO takes the form</p> \[\begin{aligned} \operatorname{ELBO}{q} &amp;= \mathbb{E}_{m \sim q(m)}\left[ logp_\theta{d_i|m} + p(m) - log q(m) \right] \\ &amp;= \mathbb{E}_{\tilde{m} \sim h(\tilde{m})}\left[ logp_\theta{d_i|g_{\phi}(\tilde{m})} + p(g_{\phi}(\tilde{m})) - log q(g_{\phi}(\tilde{m})) \right] \\ \end{aligned}\] <p>We can now differentiate through the expression w.r.t \(\phi\), in the similar way as we did for \(\theta\). To summarize, the training process transforms into:</p> <ul> <li>Sample \(d_i \sim p(d)\) <br/> \(d_i \sim p(d)\), we pass it throught the network to obtain \(q_\phi(m|d)\). Sample from \(q_{\phi}(m)\) using the reparameterization trick.</li> <li> <table> <tbody> <tr> <td>Get \(ELBO(q)\) by sampling $$m \sim q(m</td> <td>d)$$ \</td> </tr> <tr> <td>Sampling a few samples from $$q(m</td> <td>d)$$, the expectaion can be estimated.</td> </tr> </tbody> </table> </li> <li>Calculate \(\nabla_{\phi} \operatorname{ELBO}(q)\) <br/> Get the gradient using backpropagation using the reparameterization trick.</li> <li>Update \(\phi\) using gradient ascent</li> <li>Calculate \(\nabla_{\theta} \operatorname{ELBO}(q)\) <br/> We note that only the first term here is dependent on \(\theta\). \(p(m)\) is the <em>a priori</em> distribution of \(m\) and \(q(m|d)\) is parameterized on \(\phi\). For one sample, say \(m^*\), we pass it through the network to obtain the distribution \(p_\theta(d|m)\), we can easily differentiate through \(\theta\), using backpropagation.</li> <li>Update \(\theta\) using gradient ascent</li> </ul> <h2 id="for-geophysical-inversion">For geophysical inversion</h2> <p>The implementaion for probabilistic geophysical inverse problems is fairly similar. In this domain, we have the observed data \(d\) and its error bars, generally the standard deviation associated with each data point.</p> \[\begin{aligned} p(m|d) &amp; \propto p(d|m)p(m) \\ posterior \; distribution &amp; \propto likelihood * prior \; distribution \end{aligned}\] <p>The likelihood is generally the negative exponential of the misfit between the observed data and the forward response from a given model, that is</p> \[p(d|m)= \exp \left[- (\mathcal{F}(m)- d)^T W (\mathcal{F}(m)- d) \right]\] <p>where \(\mathcal{F}\) is the forward model operator and \(W\) is the weight matrix, usually the inverse of the variance in the data. The prior distribution is something where the <em>a priori</em> knowledge comes in. If in the misfit term, we were supposed to have a regularizer, say \(\| m - m_0\|^2\) for a reference model \(m_0\), then it manifests in the <em>a priori</em> distribution as</p> \[p(m)= \exp \left[- \| m - m_0\|^2 \right]\] <p>Which is just a scaled gaussian with unit variance. The posterior then becomes</p> \[p(m|d) \propto \exp \left[- (\mathcal{F}(m)- d)^T W (\mathcal{F}(m)- d) \right] \exp \left[- \| m - m_0\|^2 \right]\] <p>As is evident, we do not have to parameterize using \(\theta\). We again assume \(q_{\phi}(m)\) to approximate this posterior using variational inference. This we parameterize on \(\phi\), which can be just the parameters of the family of distribution we are using to approximate the posterior, or the weights of the network.</p> <h2 id="constraints-structure">Constraints/ Structure?</h2> <p>While constraints are included in the <em>a priori</em> term, it is worth noting that the approach to a lot of geophysical inverse problems assume that the model parameters bear no correlation with each other. However, a decent approach would have a way to incorporate structure. The mean field approximation assumes that the model parameters do not bear any correlation with each other. Would it be possible to do that by including that in the regularizer, that is the <em>a priori</em>, similar to what happens in <a href="https://marineemlab.ucsd.edu/~steve/bio/Occam1D.pdf">Occam 1D</a>, and RTO-TKO?</p> <p>OR we still sample them independently, but use a mapping that enforces the structure that is then passed into the forward operator? Remember that constraints in deep learning are applied via a similar idea, eg., using the softmax function as the last layer of the neural network to output probabilities.</p> <h1 id="references">References</h1> <ul> <li><a href="https://arxiv.org/abs/1601.00670#:~:text=One%20of%20the%20core%20problems,calculation%20involving%20the%20posterior%20density.">Variational Inference: A Review for Statisticians</a></li> <li><a href="https://youtu.be/iL1c1KmYPM0">Stanford CS330: Variational Inference and Generative Models: Lecture 11</a></li> <li><a href="https://youtu.be/-hcxTS5AXW0">2021 3.1 Variational inference, VAE’s and normalizing flows - Rianne van den Berg</a></li> </ul>]]></content><author><name></name></author><category term="probability"/><category term="inversion"/><category term="geophysics"/><category term="math"/><summary type="html"><![CDATA[Understanding variational inference and applying it to geophysical inversion]]></summary></entry><entry><title type="html">Probability</title><link href="https://ayushinav.github.io/blog/2023/probability/" rel="alternate" type="text/html" title="Probability"/><published>2023-07-06T16:40:16+00:00</published><updated>2023-07-06T16:40:16+00:00</updated><id>https://ayushinav.github.io/blog/2023/probability</id><content type="html" xml:base="https://ayushinav.github.io/blog/2023/probability/"><![CDATA[<h1 id="definitions">Definitions</h1> <p>For discrete random variable \(x\) i.i.d. from \(X= \{ x_1, x_2, \cdots x_n\}\), the probability mass function (PMF) is</p> \[f:\mathrm{R} \rightarrow [0,1] : \sum_i^n f(x_i)= 1 = \sum_{x \in X} f(x)\] <p>The cumulative distribution function (CDF) is then:</p> \[F_X(x)= \mathrm{P}(X \le x)= \sum_{i:x_i&lt;x} f(x)\] <p>A random variable is continuous if its CDF is: \(F_X(x)= \mathrm{P}(X \le x)= \int_{-\infty}^x f(u) du \quad \texttt{and} \quad f(x):\mathrm{R} \rightarrow [0, \infty] \quad \texttt{and} \quad \int_{-\infty}^{\infty} f(x)= 1\)</p> <p>where \(f(x)\) is the probability density function (PDF) of \(x\). Then</p> \[\mathrm{P}(a \le X \le b)= \int_a^b f(x) dx\] <p>Note that for a continuous variable \(X\), \(\mathrm{P}(X)= 0 \: \forall \quad X \in \mathrm{R}\), in that case</p> \[\mathrm{P}(x \le X \le x+dx)= f(x) dx\] <p>can give sense of point probability of the continuous variable.</p> <h1 id="expectation">Expectation</h1> <p>Discrete case:</p> \[\mathrm{E} \{X\} = \sum_{x\in X}x \mathrm{P}(x)\] <p>Continuous case:</p> \[\mathrm{E} \{X\}= \int_{-\infty}^{\infty} x f(x) dx\] <p>In continuous case, expectation of \(g(x)\) with \(x\) i.i.d \(f(x)\) is (replace \(x\) with \(g(x)\) in the previous eqn)</p> \[\mathrm{E} \{ g(x)\}= \int_{-\infty}^{\infty} g(x) f(x) dx\] <h1 id="joint-probability">Joint probability</h1> <p>Probability of all the events across all the variables occurring together (Imagine the independent case for intuition)</p> <p>Discrete case:</p> \[\mathrm{P}(x,y)= \mathrm{P}(x|y)\mathrm{P}(y)= \mathrm{P}(y|x)\mathrm{P}(x) \quad \texttt{(Chain rule or Baye's rule)}\] <p>When they are independent, \(\mathrm{P}(x,y)= \mathrm{P}(x) \mathrm{P}(y)\)</p> <p>Continuous case: When the variables are independent, the joint pdf \(f_{XY}(x,y)\) cannot be expressed in separable terms, when they are independent, the joint pdf can be simplified as \(f_{XY}(x,y)= f_X(x) f_Y(y)\), i.e., two separate pdfs of different variables.</p> <h1 id="marginal-probability">Marginal probability</h1> <p>Probability of event \(x\) for all outcomes of \(Y\).</p> <p>Discrete case:</p> \[\mathrm{P}(x)= \sum_{y \in Y} \mathrm{P}(x, y)= \sum_{y \in Y} \mathrm{P}(x|y)\mathrm{P}(y)\] <p>OR</p> \[\mathrm{P}(x)= \sum_{i} \mathrm{P}(x, y_i)= \sum_{i} \mathrm{P}(x|y_i)\mathrm{P}(y_i)\] <p>Continuous case:</p> \[f_X(x)= \int_{-\infty}^{\infty} f_{XY}(x,y)dy\] <h1 id="condition-probability">Condition probability</h1> <p>Probability of x happening given y happens</p> <p>Discrete case:</p> \[\mathrm{P}(x|y)= \frac{\mathrm{P}(x,y)}{p(y)}\] <p>Continuous case:</p> \[f_{X|Y}(x|Y)= \frac{f_{XY}(x,y)}{f_Y(y)}\] <h1 id="notation">Notation</h1> <p>\(X,Y\) are the domains, \(x,y\) are the specific points in those domains, the variables we work on. \(P(x)\) means \(P(X= x)\)</p> <p>CDF is just the sum of all the probabilities of all the points smaller than the current point. It’s curve is monotonically increasing. \newline Discrete case:</p> \[F_X(x)= \mathrm{P}(X \le x)= \sum_{i:x_i&lt;x} f(x)\] <p>Continuous case:</p> \[F_X(x)= \int_{-\infty}^x f(u) du \quad \texttt{OR} \quad f(x)= \frac{d}{dx} F(x)\]]]></content><author><name></name></author><category term="probability"/><category term="math"/><summary type="html"><![CDATA[Because basics are important]]></summary></entry></feed>