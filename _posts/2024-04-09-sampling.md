---
layout: post
title:  Sampling
date:   2024-04-09 16:40:16
description: Sampling from distributions
tags: probability math code
categories: 
toc:
  sidebar: left
---

# Sampling

## Exact sampling
The above integral requires us to sample from $$f(x)$$. For some simple continuous distributions, we can sample exactly. Most programming languages achieve this by generating random samples from a uniform distribution, then inverse mapping the cumulative distribution function to give a sample from the distribution. There are more details but that's the gist.

## Rejection sampling
Often, sampling from $$f(x)$$ is not feasible but therer maybe a bounding distribution $$g(x)$$ such that 

$$
f(x)/g(x) \le \alpha : 0 < \alpha < \infty  \quad \forall x \\
\implies \frac{f(x)}{\alpha g(x)} < 1
$$

In such cases, we sample from $$f(x)$$ by
* Sample $$y \sim g(\cdot)$$
* Sample $$U \sim \operatorname{Unif}[0,1]$$
* Accept $$y$$ as being drawn from $$f(\cdot)$$ when $$\frac{f(y)}{\alpha g(y)} \ge U$$

The intuition can be built from the following image:

Img : Projection of points in $$[0,1]\times[0,1]$$ with gaussian drawn on the x-axis.

Rigorously, this works because:

$$
\begin{align*}
P(Y\le y | \frac{f(y)}{\alpha g(y)} \ge U) & = \frac{P(Y\le y, \frac{f(y)}{\alpha g(y)} \ge U)}{P(\frac{f(y)}{\alpha g(y)} \ge U)} \\
& = \frac{\int_{- \infty}^{Y}  P(\frac{f(y)}{\alpha g(y)} \ge U | y =v) g(y) dy}{\int_{- \infty}^{\infty}  P(\frac{f(y)}{\alpha g(y)} \ge U | y = v) g(y) dy} \\
& = \frac{\int_{- \infty}^{Y}  \frac{f(y)}{\alpha g(y)} g(y) dy}{\int_{- \infty}^{\infty}  \frac{f(y)}{\alpha g(y)} g(y) dy} \\
& = \frac{1/\alpha \int_{- \infty}^{Y}  f(y) dy}{1/\alpha \int_{- \infty}^ {\infty} f(y) dy} \\
& = \int_{-\infty}^Y f(y) dy = P(Y \le y)
\end{align*}
$$


It should be noted that the more closely $$g(x)$$ bounds $$f(x)$$, the more points will be accepted, implying faster convergence.

## Importance Sampling

$$
\nabla^2 E - k^2 E = 0 \quad , \; k = i\omega \sigma \mu_0
$$