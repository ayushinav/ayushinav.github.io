<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Markov Chain Monte Carlo | Abhinav Pratap Singh</title> <meta name="author" content="Abhinav Pratap Singh"> <meta name="description" content="Getting organized like a Markov Chain"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://ayushinav.github.io/blog/2024/mcmc/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Abhinav </span>Pratap Singh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Markov Chain Monte Carlo</h1> <p class="post-meta">August 19, 2024</p> <p class="post-tags"> <a href="/blog/2024"> <i class="fas fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/probability"> <i class="fas fa-hashtag fa-sm"></i> probability</a>   <a href="/blog/tag/inversion"> <i class="fas fa-hashtag fa-sm"></i> inversion</a>   <a href="/blog/tag/math"> <i class="fas fa-hashtag fa-sm"></i> math</a>   </p> </header> <article class="post-content"> <h1 id="metropolis-acceptance">Metropolis acceptance</h1> <p>Markov Chain Monte Carlo (MCMC) does not need an introduction honestly. It is used to generate samples from a “target” probability distribution \(f(x)\), which is not really easy to sample. MCMC does so by constructing a Markov Chain, that is generating a new sample is only conditioned on the previous sample. More formally, this can be written as</p> \[\mathrm{P}(x^{i+1} | x^i, x^{i-1},..., x^{1}) = \mathrm{P}(x^{i+1} | x^i) = g(x^{i+1} | x^i)\] <p>where \(g( \cdot | x^i)\) is called the “proposal” distribution, and it proposes new samples from the prior distribution. The right choice of the proposal affects the convergence of MCMC. We start with the case when this proposal is symmetric, that is, there is an as chance of moving of \(x^i \rightarrow x^j\) as of \(x^j \rightarrow x^i\), that is,</p> \[g(x^{i+1} | x^i) = g(x^{i} | x^{i+1})\] <p>But for any distributions that follow the symmetry of \(g( \cdot | x^i)\), the MCMC defines a Metropolis ratio, which determines whether a proposed sample will be accepted or not. The candidate proposal \(x^*\) is accepted with the probability</p> \[\alpha(x^i, x^*) = \min \left(1, \frac{f(x^*)}{f(x^i)} \right)\] <p>Intuitively, this means that the candidate is always accepted if it is moving to a higher probability region, and is only sometimes accepted when going to the lower probability areas. The ratio inside \(\min\) is called the Metropolis ratio.</p> <h2 id="detailed-balance-and-stationary-distribution">Detailed balance and stationary distribution</h2> <p>Our objective from MCMC is to sample the posterior distribution, i.e., the samples generated at i-th and (i+1)-th step belong to the same distribution. Such a distribution which after a transition step comes back to itself is called a stationary distribution of that Markov chain. We want this stationary distribution to be the distribution we sample from. Any ergodic Markov chain that has the detailed balance sufficiently has a target stationary distribution. The detailed balance is defined as:</p> <p>\(f(x) T(x,y) = f(y) T(y,x) \implies f(x^i = x) T(x^i = x, x^{i+ 1} = y) = f(x^i = y) T(x^i= y, x^{i+1} = y)\) where \(T(x,y)\) is the transition matrix from state \(x\) to \(y\), which for our case is \(g(y|x)\) . In order to show that such a chain has a stationary distribution, we have</p> \[\begin{aligned} f_{i+1}(y) &amp;= \sum_x f_{i}(x) T(x, y) \quad \text{OR} \sum_x f_{i}(x^i = x) T(x^i = x, x^{i+ 1} = y) \\ &amp; \text{(Expressing as marginal distribution)} \\ &amp;= \sum_x f_{i}(y) T(y, x) \quad \text{OR} \sum_x f_{i}(x^i = y) T(x^i = y, x^{i+ 1} = x) \\ &amp; \text{(By detailed balance)} \\ &amp;= f_{i}(y) \sum_x T(y, x) \quad \text{OR} f_{i}(x^i = y) \sum_x T(x^i = y, x^{i+ 1} = x) \\ &amp;= f_{i}(y) \\ &amp; \text{(The summand is the sum of probabilities from any obtained value in state} x^{i} \text{ to } x^{i+1} = j, \text{which should be 1)} \\ \end{aligned}\] <p>Intuitively, detailed balance states that moving from state \(x\) to state \(y\) is as likely as the other way round, this also implies reversibility. Detailed balance enforces that the under condition of ergodicity, if the chain samples from a distribution at i-th step, it will do so in the next step.</p> <p>Now, in Metropolis algorithm, the transition probability is given by</p> \[\begin{aligned} T(x^i, x^*) &amp;= g(x^* | x^i) \alpha(x^i, x^*) \\ &amp;= g(x^* | x^i) \min \left(1, \frac{f(x^*)}{f(x^i)} \right) \\ \therefore &amp; \text{(From detailed balance)} \\ f(x^i) T(x^i, x^*) &amp;= f(x^i) g(x^* | x^i) \min \left(1, \frac{f(x^*)}{f(x^i)} \right) \\ &amp;= g(x^* | x^i) \min \left(f(x^i), f(x^*) \right) \\ &amp;= g(x^i | x^*) \min \left(f(x^i), f(x^*) \right) \\ &amp; (g(\cdot | \cdot) \text{is symmeteric for Metropolis algorithm})\\ &amp;= f(x^*) g(x^i | x^*) \min \left(1, \frac{f(x^i)}{f(x^*)} \right) \\ &amp;= f(x^*) T(x^*, x^i) \end{aligned}\] <p>Therefore, the Metropolis algorithm always has the stationary distribution defined by the “target” distribution. Though starting from a random prior point, it takes a few iterations to get to the space of exploring the posterior. This period is called burn-in and the samples generated during the time are generally ignored.</p> <p>Before we go further, the following are special cases of Metropolis algorithm.</p> <h2 id="random-walk-metropolis">Random Walk Metropolis</h2> <p>Random Walk Metropolis is a special case of the above when we choose \(g(x^i|x^j) = h(x^i -x^j)\), an example of \(h(\cdot)\) would be the normal distribution, eg.</p> <p>\(g(x^{j} | x^i) = h(x^j- x^i) = \mathrm{N}(x^j- x^i, \sigma^2) \quad \text{or} \quad x^j \sim \mathrm{N}(x^i, \sigma^2)\) We, therefore, propose a new sample that is in the vicinity of the prebious one by taking small steps, defined by \(\sigma\), in random directions. This works for simple problems, but even the step-size needs to be adequate. If it’s too small, we’re not exploring the prior space, if it’s too large, we’re wasting a lot of time on samples that may not be accepted.</p> <h2 id="independent-chain">Independent chain</h2> <p>Independent chain is another sub-class which allows the proposal to be independent of the previous state.</p> \[g(x^{j} | x^i) = h(x^j)\] <p>This might work only for very specific cases.</p> <h1 id="metropolis-hastings">Metropolis-Hastings</h1> <p>While Metropolis requires the proposal distribution \(g(\cdot | \cdot)\) be symmetric, this is not necessarily required for MCMC. In case of assymetric proposal, we modify the acceptance as:</p> \[\alpha(x^i, x^*) = \min \left(1, \frac{f(x^*) g(x^i | x^*)}{f(x^i) g(x^* | x^i)} \right)\] <p>To show that MH also has detailed balance, we have</p> \[\begin{aligned} f(x^i) T(x^i, x^*) &amp;= f(x^i) g(x^* | x^i) \min \left(1, \frac{f(x^*) g(x^i | x^*)}{f(x^i) g(x^* | x^i)} \right) \\ &amp;= \min \left(f(x^i) g(x^* | x^i), f(x^*) g(x^i | x^*) \right) \\ &amp;= f(x^*) g(x^i | x^*) \min \left(1, \frac{f(x^i) g(x^* | x^i)}{f(x^*) g(x^i | x^*)} \right) \\ &amp;= f(x^*) T(x^*, x^i) \end{aligned}\] <h2 id="references">References</h2> <ul> <li><a href="https://www2.cs.arizona.edu/~pachecoj/courses/csc535_fall20/lectures/mcmc.pdf" rel="external nofollow noopener" target="_blank">https://www2.cs.arizona.edu/~pachecoj/courses/csc535_fall20/lectures/mcmc.pdf</a></li> <li><a href="https://www.google.com/books/edition/Computational_Statistics/62OshZGXKq0C?hl=en" rel="external nofollow noopener" target="_blank">Computational Statistics</a></li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Abhinav Pratap Singh. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>